{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ddcf549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import nibabel as nib\n",
    "import pydicom\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e963567",
   "metadata": {},
   "source": [
    "# Folder Structure Before Processing\n",
    "\n",
    "Get the Dataset folder from https://github.com/ngaggion/HybridGNet which has the txt files and the groundthruth segmentation in graph format. Register at the Japanese Society of Radiological Technology website (http://db.jsrt.or.jp/eng.php) and download the .zip file containing all 247 images. Unzip the images on the Dataset/All247images folder\n",
    "\n",
    "```\n",
    "Dataset\n",
    "│   test_files.txt\n",
    "│   train_files.txt\n",
    "│   val_files.txt\n",
    "│\n",
    "└───Test\n",
    "│   │\n",
    "│   └───landmarks\n",
    "│       │   JPCLNXXX.npy\n",
    "│       │   ...\n",
    "│   \n",
    "└───Train\n",
    "│   │\n",
    "│   └───landmarks\n",
    "│       │   JPCLNXXX.npy\n",
    "│       │   ...\n",
    "│   \n",
    "└───Validation\n",
    "│   │\n",
    "│   └───landmarks\n",
    "│       │   JPCLNXXX.npy\n",
    "│       │   ...\n",
    "│\n",
    "└───All247images\n",
    "│   │ JPCLNXXX.npy\n",
    "│   │   ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383f73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBinary(img, organ, color):\n",
    "    contorno = organ.reshape(-1, 1, 2)\n",
    "\n",
    "    contorno = contorno.astype('int')\n",
    "    \n",
    "    img = cv2.drawContours(img, [contorno], -1, color, -1)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3facbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseVector(vector):\n",
    "    RLUNG = 44\n",
    "    LLUNG = 50\n",
    "    HEART = 26\n",
    "    RCLAV = 23\n",
    "    #LCLAV = 23\n",
    "    \n",
    "    p1 = RLUNG*2\n",
    "    p2 = p1 + LLUNG*2\n",
    "    p3 = p2 + HEART*2\n",
    "    p4 = p3 + RCLAV*2\n",
    "    \n",
    "    rl = vector[:p1].reshape(-1,2)\n",
    "    ll = vector[p1:p2].reshape(-1,2)\n",
    "    h = vector[p2:p3].reshape(-1,2)\n",
    "    rc = vector[p3:p4].reshape(-1,2)\n",
    "    lc = vector[p4:].reshape(-1,2)\n",
    "    \n",
    "    return rl, ll, h, rc, lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f96875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSeg(landmarks):\n",
    "    leftlung, rightlung, heart, rc, lc = reverseVector(landmarks.reshape(-1))\n",
    "\n",
    "    raw = np.zeros([1024,1024])\n",
    "    \n",
    "    raw = drawBinary(raw, leftlung, 50)\n",
    "    raw = drawBinary(raw, rightlung, 100)\n",
    "    \n",
    "    raw = drawBinary(raw, heart, 200)\n",
    "    \n",
    "    raw = drawBinary(raw, rc, 180)\n",
    "    raw = drawBinary(raw, lc, 190)\n",
    "    \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66d0c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_output(\n",
    "\n",
    "        path_input: str,\n",
    "        img: np.ndarray,\n",
    "        ext: str,\n",
    "        str_prefix: str = \"seg_\",\n",
    "        organ: str = \"\",\n",
    "    ) -> str:\n",
    "        def store_name(path_input: str, ext: str):\n",
    "            file_name_wo_ext = os.path.splitext(os.path.basename(path_input))[0]\n",
    "            file_name = str_prefix + organ + file_name_wo_ext + ext\n",
    "            parent_path = os.path.dirname(path_input).replace('landmarks', 'segments').replace('Val', 'Train')\n",
    "            os.makedirs(parent_path, exist_ok = True)\n",
    "            return os.path.join(parent_path, file_name)\n",
    "\n",
    "        recognised_ext = [\".png\", \".jpg\", \".jpeg\", \".dcm\", \".nii.gz\"]\n",
    "        if ext not in recognised_ext:\n",
    "            raise ValueError(\n",
    "                f\"{ext} not recognised. Consider using {recognised_ext} for output extensions\"\n",
    "            )\n",
    "\n",
    "        out_path = store_name(path_input, ext)\n",
    "        if img.max() <= 1:\n",
    "            img *= 255\n",
    "        if ext == \".png\" or ext == \".jpg\" or ext == \".jpeg\":\n",
    "            cv2.imwrite(out_path, img)\n",
    "\n",
    "        elif ext == \".dcm\":\n",
    "            seg_dataset = store_dcmseg(\n",
    "                source_image=pydicom.dcmread(path_input), seg_img=img, instance_number=1\n",
    "            )\n",
    "            seg_dataset.save_as(out_path)\n",
    "\n",
    "        elif ext == \".nii.gz\":\n",
    "            nifti_img = nib.Nifti1Image(img, np.eye(4))\n",
    "            nib.save(nifti_img, out_path)\n",
    "\n",
    "        return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "903f88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_npy_files = glob.glob(\"/home/ubuntu/nnUNet/JSRT/Dataset/Train/landmarks/*.npy\")\n",
    "val_npy_files = glob.glob(\"/home/ubuntu/nnUNet/JSRT/Dataset/Val/landmarks/*.npy\")\n",
    "test_npy_files = glob.glob(\"/home/ubuntu/nnUNet/JSRT/Dataset/Test/landmarks/*.npy\")\n",
    "all_npy_files = train_npy_files+ val_npy_files+ test_npy_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c2d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in all_npy_files:\n",
    "    landmarks = np.load(file)\n",
    "    landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "    store_output(file, getSeg(landmarks), '.png', str_prefix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348c9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(folderpath, flist):\n",
    "    os.makedirs(folderpath, exist_ok = True)\n",
    "    \n",
    "    for f in flist:\n",
    "        p = os.path.join('All247images', f)\n",
    "        \n",
    "        w, h = 2048, 2048 \n",
    "\n",
    "        with open(p, 'rb') as path: \n",
    "            dtype = np.dtype('>u2')\n",
    "            img = np.fromfile(path, dtype=dtype).reshape((h,w)) \n",
    "\n",
    "        img = 1 - img.astype('float')  / 4096\n",
    "        img = cv2.resize(img, (1024,1024))\n",
    "        img = img*255\n",
    "       \n",
    "        p = os.path.join(folderpath, f.replace('.IMG','.png'))\n",
    "        cv2.imwrite(p, img.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c0c899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images preprocessed\n",
      "Validation images preprocessed\n",
      "Test images preprocessed\n"
     ]
    }
   ],
   "source": [
    "trainlist = open('train_files.txt','r').read().splitlines()\n",
    "trainpath = \"Train/Images\"\n",
    "preprocess(trainpath, trainlist)\n",
    "\n",
    "print(\"Training images preprocessed\")\n",
    "\n",
    "vallist = open('val_files.txt','r').read().splitlines()\n",
    "valpath = \"Train/Images\"\n",
    "preprocess(valpath, vallist)\n",
    "\n",
    "print(\"Validation images preprocessed\")\n",
    "\n",
    "testlist = open('test_files.txt','r').read().splitlines()\n",
    "testpath = \"Test/Images\"\n",
    "preprocess(testpath, testlist)\n",
    "\n",
    "print(\"Test images preprocessed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee331f18",
   "metadata": {},
   "source": [
    "# Folder Structure After Processing\n",
    "```\n",
    "Dataset\n",
    "│   test_files.txt\n",
    "│   train_files.txt\n",
    "│   val_files.txt\n",
    "│\n",
    "└───Test\n",
    "│   │\n",
    "│   └───landmarks\n",
    "│   │   │   JPCLNXXX.npy\n",
    "│   │   │   ...\n",
    "│   │ \n",
    "│   └───segments\n",
    "│   │    │   JPCLNXXX.png\n",
    "│   │    │   ...\n",
    "│   │ \n",
    "│   └───Images\n",
    "│       │   JPCLNXXX.png\n",
    "│       │   ...\n",
    "│   \n",
    "└───Train\n",
    "│   │\n",
    "│   └───landmarks\n",
    "│   │   │   JPCLNXXX.npy\n",
    "│   │   │   ...\n",
    "│   │ \n",
    "│   └───segments\n",
    "│   │    │   JPCLNXXX.png\n",
    "│   │    │   ...\n",
    "│   │ \n",
    "│   └───Images\n",
    "│       │   JPCLNXXX.png\n",
    "│       │   ...\n",
    "│\n",
    "└───Validation\n",
    "│   │\n",
    "│   └───landmarks\n",
    "│       │   JPCLNXXX.npy\n",
    "│       │   ...\n",
    "│\n",
    "└───All247images\n",
    "│   │ JPCLNXXX.IMG\n",
    "│   │   ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321bba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
